# Core
PROJECT_NAME=hydraulic-anomaly-kappa

# Kafka
KAFKA_BROKERS=localhost:9092
KAFKA_TOPIC=hydraulic_sensor_data
KAFKA_PARTITIONS=8
KAFKA_REPLICATION_FACTOR=1

# Producer
PRODUCER_CSV_PATH=./data/hydraulic_system.csv
PRODUCER_DEVICE_ID_COLUMN=device_id
PRODUCER_KEY_FIELD=device_id
PRODUCER_SLEEP_SECONDS=0.005
PRODUCER_BATCH_SIZE=500

# Spark Streaming
SPARK_APP_NAME=HydraulicStreaming
SPARK_CHECKPOINT_DIR=hdfs://namenode:8020/user/stream/checkpoints/hydraulic
SPARK_OUTPUT_RAW=hdfs://namenode:8020/data/hydraulic/raw
SPARK_OUTPUT_AGG=hdfs://namenode:8020/data/hydraulic/aggregates
SPARK_WATERMARK_MINUTES=10
SPARK_WINDOW_MINUTES=5
SPARK_WINDOW_SLIDE_MINUTES=1

# Alerting thresholds
ALERT_COOLER_EFFICIENCY_MIN_PCT=20
ALERT_TEMPERATURE_MAX_C=75

# MongoDB serving sink
MONGO_URI=mongodb://mongo:27017
MONGO_DB=hydraulic
MONGO_ALERTS_COLLECTION=alerts
MONGO_LATEST_COLLECTION=latest_metrics

# HDFS
HDFS_NAMENODE_URI=hdfs://namenode:8020

# Batch jobs
BATCH_REPORT_LOOKBACK_HOURS=24
WEEKLY_TREND_LOOKBACK_DAYS=7
REPORTS_OUTPUT_PATH=hdfs://namenode:8020/reports/hydraulic
TRAINING_OUTPUT_PATH=hdfs://namenode:8020/models/hydraulic

# Training
TRAIN_LABEL_COLUMN=cooler_condition
TRAIN_FEATURE_COLUMNS=cooler_efficiency_pct,pressure1_bar,pressure2_bar,temperature_cooler_out_C
TRAIN_TEST_SPLIT=0.2
TRAIN_ALGORITHM=decision_tree_classifier
