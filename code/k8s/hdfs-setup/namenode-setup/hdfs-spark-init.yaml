apiVersion: batch/v1
kind: Job
metadata:
  name: hdfs-spark-init
  namespace: hdfs
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: init
        image: hadoop-python:3.8
        imagePullPolicy: Never
        command:
        - bash
        - -c
        - |
          # Wait for namenode to be ready
          echo "Waiting for NameNode..."
          until /opt/hadoop/bin/hdfs dfs -ls /; do
            sleep 5
          done
          
          echo "Waiting for SafeMode to turn OFF..."
          until /opt/hadoop/bin/hdfs dfsadmin -safemode get | grep "Safe mode is OFF"; do
            echo "NameNode is in Safe Mode..."
            sleep 5
          done
          
          echo "Preparing Spark directories in HDFS..."
          /opt/hadoop/bin/hdfs dfs -mkdir -p /user/spark/checkpoints
          /opt/hadoop/bin/hdfs dfs -mkdir -p /user/spark/raw_data/sensors
          /opt/hadoop/bin/hdfs dfs -mkdir -p /user/spark/raw_data/labels
          /opt/hadoop/bin/hdfs dfs -mkdir -p /hydraulic/raw
          /opt/hadoop/bin/hdfs dfs -mkdir -p /hydraulic/labels
          
          echo "Setting permissions..."
          /opt/hadoop/bin/hdfs dfs -chmod -R 777 /user/spark
          /opt/hadoop/bin/hdfs dfs -chmod -R 777 /hydraulic
          
          echo "HDFS Initialization Complete!"
        env:
        - name: HADOOP_CONF_DIR
          value: /etc/hadoop
        volumeMounts:
        - name: hdfs-config
          mountPath: /etc/hadoop
      volumes:
      - name: hdfs-config
        configMap:
          name: hdfs-config
