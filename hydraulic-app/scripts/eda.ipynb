{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b29e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List, Dict, Callable\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a2ac032",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"/Users/khangtuan/Documents/courses/big_data/-Hydraulic-System-Anomaly-Detection/data\"\n",
    "NUMBER_OF_PROFILES = 2205\n",
    "PROFILE_MAX_SAMPLE_RATE = 6000\n",
    "TARGET_NAMES = [\"cooler\", \"valve\", \"leakage\", \"accumulator\", \"stable\"]\n",
    "\n",
    "PLOT_STYLE = \"darkgrid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62c0a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VALUES_MAP = {\n",
    "    \"cooler\": {\n",
    "        3: \"close to total failure\",\n",
    "        20: \"reduced effifiency\",\n",
    "        100: \"full efficiency\",\n",
    "    },\n",
    "    \"valve\": {\n",
    "        100:\"optimal switching behavior\",\n",
    "        90: \"small lag\",\n",
    "        80: \"severe lag\",\n",
    "        73: \"close to total failure\",\n",
    "    }, \n",
    "    \"leakage\": {\n",
    "        0: \"no\",\n",
    "\t    1: \"weak\",\n",
    "\t    2: \"severe\",\n",
    "    },\n",
    "    \"accumulator\": {\n",
    "        130: \"optimal pressure\",\n",
    "    \t115: \"slightly reduced pressure\",\n",
    "\t    100: \"severely reduced pressure\",\n",
    "\t    90:  \"close to total failure\",\n",
    "     },\n",
    "     \"stable\":{\n",
    "        0: \"yes\",\n",
    "\t    1: \"not\",\n",
    "     }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aee2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sersor_files_config = [\n",
    "    {\"name\": \"CE\", \"upsample_coeff\": 100},\n",
    "    {\"name\": \"CP\", \"upsample_coeff\": 100},\n",
    "    {\"name\": \"EPS1\", \"upsample_coeff\": 1},\n",
    "    {\"name\": \"FS1\", \"upsample_coeff\": 10},\n",
    "    {\"name\": \"FS2\", \"upsample_coeff\": 10},\n",
    "    {\"name\": \"PS1\", \"upsample_coeff\": 1},\n",
    "    {\"name\": \"PS2\", \"upsample_coeff\": 1},\n",
    "    {\"name\": \"PS3\", \"upsample_coeff\": 1},\n",
    "    {\"name\": \"PS4\", \"upsample_coeff\": 1},\n",
    "    {\"name\": \"PS5\", \"upsample_coeff\": 1},\n",
    "    {\"name\": \"PS6\", \"upsample_coeff\": 1},\n",
    "    {\"name\": \"SE\", \"upsample_coeff\": 100},\n",
    "    {\"name\": \"TS1\", \"upsample_coeff\": 100},\n",
    "    {\"name\": \"TS2\", \"upsample_coeff\": 100},\n",
    "    {\"name\": \"TS3\", \"upsample_coeff\": 100},\n",
    "    {\"name\": \"TS4\", \"upsample_coeff\": 100},\n",
    "    {\"name\": \"VS1\", \"upsample_coeff\": 100},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39134229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_with_resample(config: List[Dict]) -> Iterable[np.ndarray]:\n",
    "    for file in config:\n",
    "        data = np.genfromtxt(PATH_TO_DATA + file[\"name\"] + \".txt\", dtype=float, delimiter='\\t')\n",
    "        yield np.repeat(data, file[\"upsample_coeff\"], axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a2cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature_dataframe(config: List[Dict]) -> pd.DataFrame:\n",
    "    columns = [file[\"name\"] for file in config]\n",
    "    data = np.stack(get_files_with_resample(config), axis=-1)\n",
    "    data_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    prodile_ids = np.repeat(range(1, NUMBER_OF_PROFILES+1), PROFILE_MAX_SAMPLE_RATE)\n",
    "    prodile_ids_df = pd.DataFrame(prodile_ids, columns=[\"profile_id\"])\n",
    "\n",
    "    return pd.concat([prodile_ids_df, data_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8702b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_targets(filename: str) -> pd.DataFrame:\n",
    "    conditions_data = np.genfromtxt(PATH_TO_DATA + filename, dtype=int, delimiter='\\t')\n",
    "    conditions_df = pd.DataFrame(conditions_data, columns=TARGET_NAMES)\n",
    "\n",
    "    prodile_ids = range(1, NUMBER_OF_PROFILES+1)\n",
    "    prodile_ids_df = pd.DataFrame(prodile_ids, columns=[\"profile_id\"])\n",
    "\n",
    "    return pd.concat([prodile_ids_df, conditions_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c39f329",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "arrays to stack must be passed as a \"sequence\" type such as list or tuple.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m feature_df = \u001b[43mload_feature_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msersor_files_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m target_df = load_targets(\u001b[33m\"\u001b[39m\u001b[33mprofile.txt\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m#Note that targets is define for profile, not to points\u001b[39;00m\n\u001b[32m      4\u001b[39m _ = gc.collect()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mload_feature_dataframe\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_feature_dataframe\u001b[39m(config: List[Dict]) -> pd.DataFrame:\n\u001b[32m      2\u001b[39m     columns = [file[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m config]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_files_with_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     data_df = pd.DataFrame(data, columns=columns)\n\u001b[32m      6\u001b[39m     prodile_ids = np.repeat(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, NUMBER_OF_PROFILES+\u001b[32m1\u001b[39m), PROFILE_MAX_SAMPLE_RATE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/courses/big_data/-Hydraulic-System-Anomaly-Detection/venv/lib/python3.12/site-packages/numpy/_core/shape_base.py:372\u001b[39m, in \u001b[36m_stack_dispatcher\u001b[39m\u001b[34m(arrays, axis, out, dtype, casting)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_stack_dispatcher\u001b[39m(arrays, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, *,\n\u001b[32m    371\u001b[39m                       dtype=\u001b[38;5;28;01mNone\u001b[39;00m, casting=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     arrays = \u001b[43m_arrays_for_stack_dispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    374\u001b[39m         \u001b[38;5;66;03m# optimize for the typical case where only arrays is provided\u001b[39;00m\n\u001b[32m    375\u001b[39m         arrays = \u001b[38;5;28mlist\u001b[39m(arrays)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/courses/big_data/-Hydraulic-System-Anomaly-Detection/venv/lib/python3.12/site-packages/numpy/_core/shape_base.py:210\u001b[39m, in \u001b[36m_arrays_for_stack_dispatcher\u001b[39m\u001b[34m(arrays)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_arrays_for_stack_dispatcher\u001b[39m(arrays):\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arrays, \u001b[33m\"\u001b[39m\u001b[33m__getitem__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33marrays to stack must be passed as a \u001b[39m\u001b[33m\"\u001b[39m\u001b[33msequence\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m type \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    211\u001b[39m                         \u001b[33m'\u001b[39m\u001b[33msuch as list or tuple.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(arrays)\n",
      "\u001b[31mTypeError\u001b[39m: arrays to stack must be passed as a \"sequence\" type such as list or tuple."
     ]
    }
   ],
   "source": [
    "feature_df = load_feature_dataframe(sersor_files_config)\n",
    "target_df = load_targets(\"profile.txt\") #Note that targets is define for profile, not to points\n",
    "\n",
    "_ = gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
