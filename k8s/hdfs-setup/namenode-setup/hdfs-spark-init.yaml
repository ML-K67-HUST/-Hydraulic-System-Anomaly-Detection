apiVersion: batch/v1
kind: Job
metadata:
  name: hdfs-spark-init
  namespace: hdfs
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: init
        image: hadoop-python:3.8
        command:
        - bash
        - -c
        - |
          # Wait for namenode to be ready
          echo "Waiting for NameNode..."
          until /opt/hadoop/bin/hdfs dfs -ls /; do
            sleep 5
          done
          
          echo "Preparing Spark directories in HDFS..."
          /opt/hadoop/bin/hdfs dfs -mkdir -p /user/spark/checkpoints
          /opt/hadoop/bin/hdfs dfs -mkdir -p /user/spark/raw_data/sensors
          /opt/hadoop/bin/hdfs dfs -mkdir -p /user/spark/raw_data/labels
          /opt/hadoop/bin/hdfs dfs -mkdir -p /hydraulic/raw
          /opt/hadoop/bin/hdfs dfs -mkdir -p /hydraulic/labels
          
          echo "Setting permissions..."
          /opt/hadoop/bin/hdfs dfs -chown -R spark:spark /user/spark
          /opt/hadoop/bin/hdfs dfs -chown -R spark:spark /hydraulic
          /opt/hadoop/bin/hdfs dfs -chmod -R 775 /user/spark
          /opt/hadoop/bin/hdfs dfs -chmod -R 775 /hydraulic
          
          echo "HDFS Initialization Complete!"
