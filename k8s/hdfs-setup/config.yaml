apiVersion: v1
kind: ConfigMap
metadata:
  name: hdfs-config
  namespace: hdfs
data:
  core-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://hdfs-namenode.hdfs.svc.cluster.local:9000</value>
        </property>
        <property>
            <name>hadoop.http.staticuser.user</name>
            <value>root</value>
        </property>
    </configuration>

  hdfs-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
        <property>
            <name>dfs.replication</name>
            <value>1</value>
        </property>
        <property>
            <name>dfs.namenode.name.dir</name>
            <value>file:///hadoop/dfs/name</value>
        </property>
        <property>
            <name>dfs.datanode.data.dir</name>
            <value>file:///hadoop/dfs/data</value>
        </property>
        <property>
            <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
            <value>false</value>
        </property>
        
        <!-- CRITICAL FIX: Bind RPC server to all interfaces -->
        <property>
            <name>dfs.namenode.rpc-bind-host</name>
            <value>0.0.0.0</value>
            <description>Bind NameNode RPC server to all network interfaces</description>
        </property>
        
        <property>
            <name>dfs.datanode.du.reserved</name>
            <value>104857600</value> <!-- 100MB -->
        </property>

        <property>
            <name>dfs.datanode.round-robin-volume-choosing-policy.additional-available-space</name>
            <value>0</value>
        </property>
        
        <!-- CRITICAL FIX: Bind HTTP server to all interfaces -->
        <property>
            <name>dfs.namenode.http-bind-host</name>
            <value>0.0.0.0</value>
            <description>Bind NameNode HTTP server to all network interfaces</description>
        </property>
        
        <!-- Service discovery hostname (what clients use) -->
        <property>
            <name>dfs.namenode.rpc-address</name>
            <value>hdfs-namenode.hdfs.svc.cluster.local:9000</value>
            <description>Advertised RPC address for clients</description>
        </property>
    </configuration>

  yarn-site.xml: |
    <?xml version="1.0"?>
    <configuration>
        <property>
            <name>yarn.log-aggregation-enable</name>
            <value>true</value>
        </property>

        <property>
            <name>yarn.log.server.url</name>
            <value>http://hdfs-resourcemanager.hdfs.svc.cluster.local:8088</value>
        </property>

        <property>
            <name>yarn.log-aggregation.retain-seconds</name>
            <value>86400</value>
        </property>

        <!-- ====== ResourceManager Hostname (CRITICAL - SHORT NAME ONLY) ====== -->
        <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>hdfs-resourcemanager</value>
            <description>Hostname for ResourceManager (SHORT NAME to avoid Hadoop RPC validation issues)</description>
        </property>
        
        <!-- ====== Server Bind Addresses (Bind to all interfaces) ====== -->
        
        <!-- ResourceManager RPC (for clients) - BIND ADDRESS -->
        <property>
            <name>yarn.resourcemanager.bind-host</name>
            <value>0.0.0.0</value>
            <description>Bind all RM RPC services to all interfaces</description>
        </property>
        
        <!-- ResourceManager Web UI - BIND ADDRESS -->
        <property>
            <name>yarn.resourcemanager.webapp.bind-host</name>
            <value>0.0.0.0</value>
            <description>Bind RM Web UI to all interfaces</description>
        </property>
        
        <!-- ====== Client-Facing Addresses (Auto-derived from hostname) ====== -->
        
        <property>
            <name>yarn.resourcemanager.address</name>
            <value>${yarn.resourcemanager.hostname}:8032</value>
            <description>ResourceManager RPC address for clients</description>
        </property>
        
        <property>
            <name>yarn.resourcemanager.scheduler.address</name>
            <value>${yarn.resourcemanager.hostname}:8030</value>
            <description>Scheduler RPC address</description>
        </property>
        
        <property>
            <name>yarn.resourcemanager.resource-tracker.address</name>
            <value>${yarn.resourcemanager.hostname}:8031</value>
            <description>Resource tracker address for NodeManagers</description>
        </property>
        
        <property>
            <name>yarn.resourcemanager.admin.address</name>
            <value>${yarn.resourcemanager.hostname}:8033</value>
            <description>Admin RPC address</description>
        </property>
        
        <property>
            <name>yarn.resourcemanager.webapp.address</name>
            <value>${yarn.resourcemanager.hostname}:8088</value>
            <description>Web UI address</description>
        </property>
        
        <!-- ====== NodeManager Configuration ====== -->
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
        </property>
        
        <property>
            <name>yarn.nodemanager.resource.memory-mb</name>
            <value>4096</value>
        </property>
        
        <property>
            <name>yarn.nodemanager.resource.cpu-vcores</name>
            <value>3</value>
            <description>3 vCores for YARN containers (local machine)</description>
        </property>
        
        <property>
            <name>yarn.nodemanager.bind-host</name>
            <value>0.0.0.0</value>
            <description>Bind NodeManager to all interfaces</description>
        </property>

        <property>
            <name>yarn.nodemanager.hostname</name>
            <value>hdfs-nodemanager</value>
        </property>

        <property>
            <name>yarn.nodemanager.local-dirs</name>
            <value>/tmp/hadoop-yarn/nm-local-dir</value>
        </property>
        
        <property>
            <name>yarn.nodemanager.log-dirs</name>
            <value>/var/log/hadoop/userlogs</value>
        </property>

        <property>
            <name>yarn.nodemanager.disk-health-checker.max-disk-utilization-percents</name>
            <value>98.0</value>
        </property>
        
        <!-- ====== Scheduler Configuration ====== -->
        <property>
            <name>yarn.scheduler.maximum-allocation-mb</name>
            <value>4096</value>
            <description>Max 4GB per container (local machine)</description>
        </property>
        
        <property>
            <name>yarn.scheduler.maximum-allocation-vcores</name>
            <value>2</value>
            <description>Max 2 vCores per container (local machine)</description>
        </property>
        
        <property>
            <name>yarn.scheduler.minimum-allocation-mb</name>
            <value>512</value>
        </property>
        
        <property>
            <name>yarn.scheduler.minimum-allocation-vcores</name>
            <value>1</value>
        </property>
    </configuration>

  mapred-site.xml: |
    <?xml version="1.0"?>
    <configuration>
        <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
        <property>
            <name>mapreduce.application.classpath</name>
            <value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
        </property>
        <property>
            <name>mapred.child.java.opts</name>
            <value>-Xmx1024m</value>
        </property>
        <property>
            <name>mapreduce.map.memory.mb</name>
            <value>1024</value>
        </property>
        <property>
            <name>mapreduce.reduce.memory.mb</name>
            <value>1024</value>
        </property>
        <property>
            <name>mapreduce.map.java.opts</name>
            <value>-Xmx768m</value>
        </property>
        <property>
            <name>mapreduce.reduce.java.opts</name>
            <value>-Xmx768m</value>
        </property>
    </configuration>

  capacity-scheduler.xml: |
    <?xml version="1.0"?>
    <configuration>
      <!-- Root Queue Configuration -->
      <property>
        <name>yarn.scheduler.capacity.maximum-am-resource-percent</name>
        <value>0.8</value>
        <description>Maximum percent of resources in the cluster which can be used to run application masters.</description>
      </property>

      <property>
        <name>yarn.scheduler.capacity.root.queues</name>
        <value>default</value>
        <description>The queues at the root level (root is the root queue).</description>
      </property>

      <!-- Default Queue Configuration -->
      <property>
        <name>yarn.scheduler.capacity.root.default.capacity</name>
        <value>100</value>
        <description>Default queue target capacity.</description>
      </property>

      <property>
        <name>yarn.scheduler.capacity.root.default.maximum-capacity</name>
        <value>100</value>
        <description>Default queue maximum capacity.</description>
      </property>

      <property>
        <name>yarn.scheduler.capacity.root.default.state</name>
        <value>RUNNING</value>
        <description>The state of the default queue. Can be RUNNING or STOPPED.</description>
      </property>

      <property>
        <name>yarn.scheduler.capacity.root.default.acl_submit_applications</name>
        <value>*</value>
        <description>ACL for who can submit apps to default queue.</description>
      </property>

      <property>
        <name>yarn.scheduler.capacity.root.default.acl_administer_queue</name>
        <value>*</value>
        <description>ACL for who can administer default queue.</description>
      </property>

      <property>
        <name>yarn.scheduler.capacity.root.default.maximum-allocation-mb</name>
        <value>4096</value>
        <description>Maximum memory allocation for a single container.</description>
      </property>

      <property>
        <name>yarn.scheduler.capacity.root.default.maximum-allocation-vcores</name>
        <value>2</value>
        <description>Maximum vcore allocation for a single container.</description>
      </property>

      <!-- Queue Mapping -->
      <property>
        <name>yarn.scheduler.capacity.queue-mappings</name>
        <value></value>
        <description>Queue mapping for users.</description>
      </property>

      <property>
        <name>yarn.scheduler.capacity.queue-mappings-override.enable</name>
        <value>false</value>
        <description>Override user-specified queues.</description>
      </property>

      <!-- Node Labels (Optional) -->
      <property>
        <name>yarn.scheduler.capacity.root.accessible-node-labels</name>
        <value>*</value>
      </property>

      <property>
        <name>yarn.scheduler.capacity.root.default.accessible-node-labels</name>
        <value>*</value>
      </property>
    </configuration>